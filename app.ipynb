{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e110dd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198171f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Collecting tzlocal<6,>=1.1\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Collecting validators<1,>=0.2\n",
      "  Using cached validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (8.1.0)\n",
      "Collecting pandas<3,>=1.3.0\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Collecting watchdog>=2.1.5\n",
      "  Using cached watchdog-3.0.0-py3-none-win_amd64.whl (82 kB)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (12.6.0)\n",
      "Collecting pyarrow>=6.0\n",
      "  Downloading pyarrow-14.0.1-cp38-cp38-win_amd64.whl (24.6 MB)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (20.9)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (1.20.1)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (8.2.0)\n",
      "Collecting altair<6,>=4.0\n",
      "  Using cached altair-5.1.2-py3-none-any.whl (516 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Downloading protobuf-4.25.1-cp38-cp38-win_amd64.whl (413 kB)\n",
      "Collecting requests<3,>=2.27\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (4.5.0)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in d:\\python\\anaconda\\lib\\site-packages (from streamlit) (5.0.0)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "Requirement already satisfied: toolz in d:\\python\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\python\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\python\\anaconda\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.4.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in d:\\python\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: setuptools in d:\\python\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (52.0.0.post20210125)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\python\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\python\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\anaconda\\lib\\site-packages (from packaging<24,>=16.8->streamlit) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python\\anaconda\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2021.1)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting python-dateutil<3,>=2.7.3\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting numpy<2,>=1.19.3\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\python\\anaconda\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in d:\\python\\anaconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.8.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in d:\\python\\anaconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (0.9.1)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-win_amd64.whl (38 kB)\n",
      "Installing collected packages: tzdata, smmap, python-dateutil, numpy, pandas, gitdb, backports.zoneinfo, watchdog, validators, tzlocal, requests, pydeck, pyarrow, protobuf, gitpython, blinker, altair, streamlit\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\n",
      "mediapipe 0.9.0.1 requires protobuf<4,>=3.11, but you have protobuf 4.25.1 which is incompatible.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.1 which is incompatible.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.1 which is incompatible.\n",
      "spyder 4.2.5 requires watchdog<2.0.0,>=0.10.3, but you have watchdog 3.0.0 which is incompatible.\n",
      "scipy 1.6.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: watchdog\n",
      "    Found existing installation: watchdog 1.0.2\n",
      "    Uninstalling watchdog-1.0.2:\n",
      "      Successfully uninstalled watchdog-1.0.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed altair-5.1.2 backports.zoneinfo-0.2.1 blinker-1.7.0 gitdb-4.0.11 gitpython-3.1.40 numpy-1.24.4 pandas-2.0.3 protobuf-4.25.1 pyarrow-14.0.1 pydeck-0.8.1b0 python-dateutil-2.8.2 requests-2.31.0 smmap-5.0.1 streamlit-1.28.2 tzdata-2023.3 tzlocal-5.2 validators-0.22.0 watchdog-3.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4698092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model= pickle.load(open(\"new_random_forest_model.pkl\", 'rb'))\n",
    "def main():\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "            body {\n",
    "                background-image: url('https://images.pexels.com/photos/440731/pexels-photo-440731.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1');\n",
    "                background-size: cover;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "    st.title(\"Crop Recommendation App\")\n",
    "\n",
    "    # Input form for user\n",
    "    temp = st.slider(\"Temperature\", min_value=0.0, max_value=60.0, step=0.1, value=25.0)\n",
    "    rainfall = st.slider(\"Rainfall\", min_value=0.0, max_value=1200.0, step=0.1, value=50.0)\n",
    "    humidity = st.slider(\"Humidity\", min_value=0.0, max_value=100.0, step=0.1, value=60.0)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction_button = st.button(\"Predict Crop\")\n",
    "    if prediction_button:\n",
    "        input_data = np.array([[temp, rainfall, humidity]])\n",
    "        prediction = model.predict(input_data)\n",
    "        crop = get_crop(prediction)\n",
    "        st.success(f\"The recommended crop is: {crop}\")\n",
    "\n",
    "# Helper function to map predicted label to crop\n",
    "def get_crop(prediction):\n",
    "    crop_mapping = {\n",
    "        0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea', \n",
    "        4: 'coconut', 5: 'coffee', 6: 'cotton', \n",
    "        7: 'grapes',8: 'jute', 9: 'kidneybeans', \n",
    "        10: 'lentil', 11: 'maize', 12: 'mango', \n",
    "        13: 'mothbeans', 14: 'mungbean',15: 'muskmelon', \n",
    "        16: 'orange', 17: 'papaya', 18: 'pigeonpeas', \n",
    "        19: 'pomegranate', \n",
    "        20: 'rice', 21: 'watermelon'\n",
    "    }\n",
    "    return crop_mapping.get(prediction[0], \"Unknown Crop\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0158af64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4957a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting complete_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile complete_app.py\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = pickle.load(open(\"new_random_forest_model.pkl\", 'rb'))\n",
    "\n",
    "# Load the saved LSTM model\n",
    "with open(\"lstm_forecast_model.pkl\", \"rb\") as file:\n",
    "    lstm_model = pickle.load(file)\n",
    "\n",
    "def get_crop(prediction):\n",
    "    crop_mapping = {\n",
    "        0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea', \n",
    "        4: 'coconut', 5: 'coffee', 6: 'cotton', \n",
    "        7: 'grapes', 8: 'jute', 9: 'kidneybeans', \n",
    "        10: 'lentil', 11: 'maize', 12: 'mango', \n",
    "        13: 'mothbeans', 14: 'mungbean', 15: 'muskmelon', \n",
    "        16: 'orange', 17: 'papaya', 18: 'pigeonpeas', \n",
    "        19: 'pomegranate', \n",
    "        20: 'rice', 21: 'watermelon'\n",
    "    }\n",
    "    return crop_mapping.get(prediction[0], \"Unknown Crop\")\n",
    "\n",
    "def show_crop_calendar():\n",
    "    # Load your Excel sheet with crop calendar\n",
    "    # Replace 'your_crop_calendar.xlsx' with the actual filename or path\n",
    "    crop_calendar = pd.read_excel('CROPCALENDAR.xlsx')\n",
    "\n",
    "    # Display the crop calendar as a Markdown table\n",
    "    st.title(\"Crop Calendar\")\n",
    "\n",
    "    # Convert DataFrame to Markdown table\n",
    "    markdown_table = crop_calendar.to_markdown(index=False)\n",
    "\n",
    "    # Display Markdown table\n",
    "    st.markdown(markdown_table, unsafe_allow_html=True)\n",
    "\n",
    "def forecast_page():\n",
    "    st.title(\"Division-wise Forecast\")\n",
    "\n",
    "    # Define divisions and their corresponding CSV files\n",
    "    division_files = {\n",
    "        \"Pune\": \"pune_forecast.csv\",\n",
    "        \"Nagpur\": \"nagpur_forecast.csv\",\n",
    "        \"Nashik\": \"nashik_forecast.csv\",\n",
    "        \"Aurangabad\": \"aurangabad_forecast.csv\",\n",
    "        \"Amravati\": \"amravati_forecast.csv\",\n",
    "        \"Konkan\": \"konkan_forecast.csv\",\n",
    "    }\n",
    "\n",
    "    # User selects a division\n",
    "    selected_division = st.selectbox(\"Select Division\", list(division_files.keys()))\n",
    "\n",
    "    # Load the corresponding CSV file for the selected division\n",
    "    file_path = division_files[selected_division]\n",
    "    forecast_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the forecast results in a table\n",
    "    st.write(f\"Forecast Results for {selected_division}:\")\n",
    "    st.dataframe(forecast_data)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Crop Recommendation App\")\n",
    "\n",
    "    # Create buttons for navigation\n",
    "    predict_crop_button = st.button(\"Predict Crop\", key=\"predict_crop_button\")\n",
    "    forecast_button = st.button(\"Forecast\", key=\"forecast_button\")\n",
    "\n",
    "    # Check button clicks and navigate to respective pages\n",
    "    if predict_crop_button:\n",
    "        st.session_state.page = \"Predict Crop\"\n",
    "    elif forecast_button:\n",
    "        st.session_state.page = \"Forecast\"\n",
    "\n",
    "    # Display content based on the selected page\n",
    "    if \"page\" not in st.session_state:\n",
    "        st.session_state.page = \"Home\"\n",
    "\n",
    "    if st.session_state.page == \"Predict Crop\":\n",
    "        st.write(\"Welcome to the Predict Crop page!\")\n",
    "        # Input form for user\n",
    "        temp = st.slider(\"Temperature\", min_value=0.0, max_value=60.0, step=0.1, value=25.0)\n",
    "        rainfall = st.slider(\"Rainfall\", min_value=0.0, max_value=1200.0, step=0.1, value=50.0)\n",
    "        humidity = st.slider(\"Humidity\", min_value=0.0, max_value=100.0, step=0.1, value=60.0)\n",
    "        \n",
    "        # Make prediction\n",
    "        if st.button(\"Predict Crop\"):\n",
    "            input_data = np.array([[temp, rainfall, humidity]])\n",
    "            prediction = model.predict(input_data)\n",
    "            crop = get_crop(prediction)\n",
    "            st.success(f\"The recommended crop is: {crop}\")\n",
    "\n",
    "        # Add button to show crop calendar \n",
    "        if st.button(\"See Crop Calendar for Maharashtra State\"):\n",
    "            show_crop_calendar()\n",
    "\n",
    "    elif st.session_state.page == \"Forecast\":\n",
    "        forecast_page()\n",
    "    else:\n",
    "        st.write(\"Welcome to the Home page!\")\n",
    "        # Add your content for the Home page here\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ccdbc3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df72f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ad1f7b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting complete_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile complete_app.py\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"lstm_forecast_model.pkl\", \"rb\") as file:\n",
    "    lstm_model = pickle.load(file)\n",
    "model = pickle.load(open(\"new_random_forest_model.pkl\", 'rb'))\n",
    "\n",
    "def get_crop(prediction):\n",
    "    crop_mapping = {\n",
    "        0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea', \n",
    "        4: 'coconut', 5: 'coffee', 6: 'cotton', \n",
    "        7: 'grapes', 8: 'jute', 9: 'kidneybeans', \n",
    "        10: 'lentil', 11: 'maize', 12: 'mango', \n",
    "        13: 'mothbeans', 14: 'mungbean', 15: 'muskmelon', \n",
    "        16: 'orange', 17: 'papaya', 18: 'pigeonpeas', \n",
    "        19: 'pomegranate', \n",
    "        20: 'rice', 21: 'watermelon'\n",
    "    }\n",
    "    return crop_mapping.get(prediction[0], \"Unknown Crop\")\n",
    "\n",
    "def show_crop_calendar():\n",
    "    # Load your Excel sheet with crop calendar\n",
    "    # Replace 'your_crop_calendar.xlsx' with the actual filename or path\n",
    "    crop_calendar = pd.read_excel('CROPCALENDAR.xlsx')\n",
    "\n",
    "    # Display the crop calendar as a Markdown table\n",
    "    st.title(\"Crop Calendar\")\n",
    "\n",
    "    # Convert DataFrame to Markdown table\n",
    "    markdown_table = crop_calendar.to_markdown(index=False)\n",
    "\n",
    "    # Display Markdown table\n",
    "    st.markdown(markdown_table, unsafe_allow_html=True)\n",
    "# Load the saved LSTM model\n",
    "\n",
    "def forecast_page():\n",
    "    st.title(\"Division-wise Forecast\")\n",
    "\n",
    "    # Define divisions and their corresponding CSV files\n",
    "    division_files = {\n",
    "        \"Pune\": \"pune_forecast.csv\",\n",
    "        \"Nagpur\": \"nagpur_forecast.csv\",\n",
    "        \"Nashik\": \"nashik_forecast.csv\",\n",
    "        \"Aurangabad\": \"aurangabad_forecast.csv\",\n",
    "        \"Amravati\": \"amravati_forecast.csv\",\n",
    "        \"Konkan\": \"konkan_forecast.csv\",\n",
    "    }\n",
    "\n",
    "    # User selects a division\n",
    "    selected_division = st.selectbox(\"Select Division\", list(division_files.keys()))\n",
    "\n",
    "    # Load the corresponding CSV file for the selected division\n",
    "    file_path = division_files[selected_division]\n",
    "    forecast_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the forecast results in a table\n",
    "    st.write(f\"Forecast Results for {selected_division}:\")\n",
    "    st.dataframe(forecast_data)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Crop Recommendation App\")\n",
    "\n",
    "    # Create buttons for navigation\n",
    "    predict_crop_button = st.button(\"Predict Crop\", key=\"predict_crop_button\")\n",
    "    forecast_button = st.button(\"Forecast\", key=\"forecast_button\")\n",
    "\n",
    "    # Check button clicks and navigate to respective pages\n",
    "    if predict_crop_button:\n",
    "        st.session_state.page = \"Predict Crop\"\n",
    "    elif forecast_button:\n",
    "        st.session_state.page = \"Forecast\"\n",
    "\n",
    "    # Display content based on the selected page\n",
    "    if \"page\" not in st.session_state:\n",
    "        st.session_state.page = \"Home\"\n",
    "\n",
    "    if st.session_state.page == \"Predict Crop\":\n",
    "        st.write(\"Welcome to the Predict Crop page!\")\n",
    "        # Add your content for the Predict Crop page here\n",
    "    elif st.session_state.page == \"Forecast\":\n",
    "        forecast_page()\n",
    "    else:\n",
    "        st.write(\"Welcome to the Home page!\")\n",
    "        # Add your content for the Home page here\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3261f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run complete_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6463196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo_app.py\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved Random Forest model\n",
    "model = pickle.load(open(\"new_random_forest_model.pkl\", 'rb'))\n",
    "\n",
    "# Load the saved LSTM model\n",
    "with open(\"lstm_forecast_model.pkl\", \"rb\") as file:\n",
    "    lstm_model = pickle.load(file)\n",
    "\n",
    "def get_crop(prediction):\n",
    "    crop_mapping = {\n",
    "        0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea', \n",
    "        4: 'coconut', 5: 'coffee', 6: 'cotton', \n",
    "        7: 'grapes', 8: 'jute', 9: 'kidneybeans', \n",
    "        10: 'lentil', 11: 'maize', 12: 'mango', \n",
    "        13: 'mothbeans', 14: 'mungbean', 15: 'muskmelon', \n",
    "        16: 'orange', 17: 'papaya', 18: 'pigeonpeas', \n",
    "        19: 'pomegranate', \n",
    "        20: 'rice', 21: 'watermelon'\n",
    "    }\n",
    "    return crop_mapping.get(prediction[0], \"Unknown Crop\")\n",
    "\n",
    "def predict_crop():\n",
    "    st.title(\"Predict Crop\")\n",
    "\n",
    "    # Input form for user\n",
    "    temp = st.slider(\"Temperature\", min_value=0.0, max_value=60.0, step=0.1, value=25.0)\n",
    "    rainfall = st.slider(\"Rainfall\", min_value=0.0, max_value=1200.0, step=0.1, value=50.0)\n",
    "    humidity = st.slider(\"Humidity\", min_value=0.0, max_value=100.0, step=0.1, value=60.0)\n",
    "\n",
    "    # Make prediction\n",
    "    if st.button(\"Predict Crop\"):\n",
    "        input_data_point = np.array([[temp, rainfall, humidity]])\n",
    "        prediction = model.predict(input_data_point)\n",
    "        crop = get_crop(prediction)\n",
    "        st.success(f\"The recommended crop is: {crop}\")\n",
    "\n",
    "def show_crop_calendar():\n",
    "    # Load your Excel sheet with crop calendar\n",
    "    # Replace 'your_crop_calendar.xlsx' with the actual filename or path\n",
    "    crop_calendar = pd.read_excel('CROPCALENDAR.xlsx')\n",
    "\n",
    "    # Display the crop calendar as a Markdown table\n",
    "    st.title(\"Crop Calendar\")\n",
    "\n",
    "    # Convert DataFrame to Markdown table\n",
    "    markdown_table = crop_calendar.to_markdown(index=False)\n",
    "\n",
    "    # Display Markdown table\n",
    "    st.markdown(markdown_table, unsafe_allow_html=True)\n",
    "\n",
    "def forecast_page():\n",
    "    st.title(\"Division-wise Forecast\")\n",
    "\n",
    "    # Define divisions and their corresponding CSV files\n",
    "    division_files = {\n",
    "        \"Pune\": \"pune_forecast.csv\",\n",
    "        \"Nagpur\": \"nagpur_forecast.csv\",\n",
    "        \"Nashik\": \"nashik_forecast.csv\",\n",
    "        \"Aurangabad\": \"aurangabad_forecast.csv\",\n",
    "        \"Amravati\": \"amravati_forecast.csv\",\n",
    "        \"Konkan\": \"konkan_forecast.csv\",\n",
    "    }\n",
    "\n",
    "    # User selects a division\n",
    "    selected_division = st.selectbox(\"Select Division\", list(division_files.keys()))\n",
    "\n",
    "    # Load the corresponding CSV file for the selected division\n",
    "    file_path = division_files[selected_division]\n",
    "    forecast_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the forecast results in a table\n",
    "    st.write(f\"Forecast Results for {selected_division}:\")\n",
    "    st.dataframe(forecast_data)\n",
    "\n",
    "    # Add button to predict crops for this forecast\n",
    "    predict_crops_for_input_data(forecast_data)\n",
    "    \n",
    "    uploaded_file = st.file_uploader(f\"Upload CSV file to get forecasts\", type=\"csv\")\n",
    "\n",
    "def predict_crops_for_input_data(input_data):\n",
    "    st.title(\"Estimate crop based on forecasts\")\n",
    "\n",
    "    # Add button to predict crops for each row\n",
    "    if st.button(\"Predict Crops\"):\n",
    "        for index, row in input_data.iterrows():\n",
    "            temperature = (row['MMIN'] + row['MMAX']) / 2\n",
    "            rainfall = row['TMRF']\n",
    "            humidity = row['Humidity']\n",
    "\n",
    "            input_data_point = np.array([[temperature, rainfall, humidity]])\n",
    "            prediction_probabilities = model.predict_proba(input_data_point)[0]\n",
    "            top_crops = get_top_crops(prediction_probabilities, k=5)\n",
    "\n",
    "            st.success(f\"Top 5 estimated crops for row {index + 1}:\")\n",
    "            for i, (crop, probability) in enumerate(top_crops, 1):\n",
    "                st.write(f\"{i}.{crop}\")\n",
    "\n",
    "def get_top_crops(probabilities, k=5):\n",
    "    # Get indices of the top k probabilities\n",
    "    top_indices = np.argsort(probabilities)[::-1][:k]\n",
    "\n",
    "    # Map indices to crop names and probabilities\n",
    "    top_crops = [(get_crop_label(index), probabilities[index]) for index in top_indices]\n",
    "\n",
    "    return top_crops\n",
    "\n",
    "def get_crop_label(prediction):\n",
    "    crop_mapping = {\n",
    "        0: 'apple', 1: 'banana', 2: 'blackgram', 3: 'chickpea',\n",
    "        4: 'coconut', 5: 'coffee', 6: 'cotton',\n",
    "        7: 'grapes', 8: 'jute', 9: 'kidneybeans',\n",
    "        10: 'lentil', 11: 'maize', 12: 'mango',\n",
    "        13: 'mothbeans', 14: 'mungbean', 15: 'muskmelon',\n",
    "        16: 'orange', 17: 'papaya', 18: 'pigeonpeas',\n",
    "        19: 'pomegranate',\n",
    "        20: 'rice', 21: 'watermelon'\n",
    "    }\n",
    "    \n",
    "    return crop_mapping.get(int(prediction), \"Unknown Crop\")\n",
    "\n",
    "def main():\n",
    "    st.title(\"Crop Recommendation App\")\n",
    "    \n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(\"https://media.gettyimages.com/id/1724875987/photo/corn-field-sunset.jpg?s=612x612&w=0&k=20&c=DjVgnMIeoV8eX71HhDBHG7kp9iPQ8y_TId5Ee_enidE=\");\n",
    "            background-attachment: fixed;\n",
    "            background-size: cover;\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "    # Create buttons for navigation on the home page\n",
    "    predict_crop_button = st.button(\"Predict Crop\", key=\"predict_crop_button\")\n",
    "    forecast_button = st.button(\"See Forecasts\", key=\"forecast_button\")\n",
    "    crop_calendar_button = st.button(\"See Crop Calendar for Maharashtra State\", key=\"crop_calendar_button\")\n",
    "\n",
    "    # Check button clicks and navigate to respective pages\n",
    "    if predict_crop_button:\n",
    "        st.session_state.page = \"Predict Crop\"\n",
    "    elif forecast_button:\n",
    "        st.session_state.page = \"Forecast\"\n",
    "    elif crop_calendar_button:\n",
    "        st.session_state.page = \"Crop Calendar\"\n",
    "\n",
    "    # Display content based on the selected page\n",
    "    if \"page\" not in st.session_state:\n",
    "        st.session_state.page = \"Home\"\n",
    "\n",
    "    if st.session_state.page == \"Predict Crop\":\n",
    "        predict_crop()\n",
    "\n",
    "    elif st.session_state.page == \"Forecast\":\n",
    "        forecast_page()\n",
    "\n",
    "    elif st.session_state.page == \"Crop Calendar\":\n",
    "        show_crop_calendar()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run demo_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc447fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
